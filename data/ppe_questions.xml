<?xml version="1.0" encoding="UTF-8" ?>

<exam xmlns="https://vpt1.org"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
      xsi:schemaLocation="https://vpt1.org questions.xsd">
    <head>
        <title>Parallel Program Engineering Questions</title>
        <version>1.0</version>
        <id>4224</id>
    </head>
    <body>
        <!-- Terminology -->
        <question type="extended-answer" id="-1">
            <body>What is the difference between a node, socket, core, and a (HW) thread?</body>
            <answers>
                <answer>
                    <body>A node is interconnected by network
                        <p/>
                        A node contains one or more physical sockets that mount the CPU
                        <p/>
                    </body>
                    <marks></marks>
                </answer>
            </answers>
        </question>


        <!-- From Recap Handwritten Notes on Presentations -->

        <!-- Variability -->
        <question type="extended-answer" id="0">
            <body>What are some hardware/software reasons that running a program on identical hardware can lead to
                different results? What is the consequence?
            </body>
            <answers>
                <answer>
                    <body>Hardware: Same chip can vary under different conditions (such as temperature/thermal
                        throttling). A different chip of the same model can vary due to production differences in the
                        same conditions.
                        <p/>
                        Software: Any resources that are shared (cpu, network, etc.) can be contended, OS-Scheduling and
                        energy-saving features, etc.
                        <p/>
                        Consequence: Don't expect same performance between any 2 different runs, treat runs as a
                        stochastic experiment. Repeat it as many times as necessary.
                    </body>
                    <marks>
                        <mark type="keyword">temp</mark>
                        <mark type="keyword">sched</mark>
                        <mark type="keyword">experiment</mark>
                        <mark type="keyword">rep</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="1">
            <body>How can variability be mitigated?</body>
            <answers>
                <answer>
                    <body>
                        Work with data stochastically
                        <p/>
                        Conduct multiple experiments
                        <p/>
                        Measure variance/confidence interval
                        <p/>
                        Try to control as much of the environment as possible
                        <p/>
                        Ensure there is a good spread over uncontrollable environment influences (measure on different
                        days, etc.)
                        <p/>
                        Be skeptical about results, look for unexpected changes in the environment.
                    </body>
                    <marks>
                        <mark type="keyword">stochast</mark>
                        <mark type="keyword">experiment</mark>
                        <mark type="keyword">environment</mark>
                        <mark type="keyword">control</mark>
                    </marks>
                </answer>
            </answers>
        </question>

        <!-- Overhead and Intrusion -->

        <question type="extended-answer" id="2">
            <body>What does Score-P do?</body>
            <answers>
                <answer>
                    <body>TODO</body>
                    <marks></marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="3">
            <body>What do you need to look out for when using Score-P?</body>
            <answers>
                <answer>
                    <body>Unexpected or unintended flushes of the log file from memory to permanent storage, which cause
                        overhead and affect code execution.
                        <p/>
                        Identify overhead by looking at the execution time.
                    </body>
                    <marks>
                        <mark type="keyword">flush</mark>
                        <mark type="keyword">overhead</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="4">
            <body>What methods are available to reduce the log size in Score-P?</body>
            <answers>
                <answer>
                    <body>Compile time filtering, selective region filter (user regions), switching tracing on/off.
                    </body>
                    <marks>
                        <mark type="keyword">compile</mark>
                        <mark type="keyword">region</mark>
                        <mark type="keyword">filter</mark>
                        <mark type="keyword">trac</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="5">
            <body>What are selective region filters (user regions) in Score-P?</body>
            <answers>
                <answer>
                    <body>TODO</body>
                    <marks></marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="6">
            <body>What is the problem with runtime filtering? How can it be minimized?</body>
            <answers>
                <answer>
                    <body>There still needs to be a check whether this event should be logged. Good implementations can
                        patch this out by running an uninstrumented version of the code instead. However, some amount of
                        overhead remains.
                    </body>
                    <marks>
                        <mark type="keyword">check</mark>
                        <mark type="keyword">patch</mark>
                        <mark type="keyword">overhead</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="7">
            <body>What are some pros/cons for compile time vs runtime filtering? How are these filters used?</body>
            <answers>
                <answer>
                    <body>Compile time gets rids of all overhead that is unnecessary (because of filtering, etc.). It is
                        set by passing a flag to scorep_compile with the filter file.
                        <p/>
                        Runtime filtering allows for easier change of the filter and does not require recompilation of
                        the source. It is set by setting an environment variable.
                    </body>
                    <marks>
                        <mark type="keyword">overhead</mark>
                        <mark type="keyword">filter</mark>
                        <mark type="keyword">flag</mark>
                        <mark type="keyword">compil</mark>
                        <mark type="keyword">variable</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="8">
            <body>How can one estimate the memory requirements of a run through scorep? What is this useful for?</body>
            <answers>
                <answer>
                    <body>Using the bundled tool scorep_score, which shows you the memory requirements and warns about
                        potential flushes. It allows you to optimize your filters for memory requirements without
                        actually running your instrumented code.
                    </body>
                    <marks>
                        <mark type="keyword">score</mark>
                    </marks>
                </answer>
            </answers>
        </question>

        <!-- More Terminology -->

        <question type="extended-answer" id="9">
            <body>What is the difference between tracing and profiling? What are some benefits and drawbacks of each?
            </body>
            <answers>
                <answer>
                    <body>Tracing records information on every single call, while profiling only shows aggregate
                        information (e.g. how often a function was called, etc.). Tracing can be used to inspect
                        individual problematic calls but generally creates more overhead than profiling, which is less
                        detailed and therefore also generates less overhead.
                    </body>
                    <marks>
                        <mark type="keyword">call</mark>
                        <mark type="keyword">aggregat</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="10">
            <body>What is sampling and instrumentation? What are some benefits and drawbacks of
                each?
            </body>
            <answers>
                <answer>
                    <body>A sampling based approach halts the program periodically to analyze the program's current
                        state. An instrumentation approach modifies the program to add additional code, for example at
                        the start and end of a method, that performs measurements itself.
                        <p/>
                        Sampling does not require modification of the code/binary and can even be adjusted at runtime.
                        However, it is a stochastic approach and can "miss" calls to functions and other events.
                        Instrumentation, on the other hand, does not miss anything. However, it usually needs more
                        fine-tuning to get the level of overhead to an acceptable level without loosing important
                        details.
                    </body>
                    <marks>
                        <mark type="keyword">measure</mark>
                        <mark type="keyword">overhead</mark>
                        <mark type="keyword">stochast</mark>
                        <mark type="keyword">modif</mark>
                    </marks>
                </answer>
            </answers>
        </question>

        <!-- Single Node Performance -->

        <question type="extended-answer" id="1000">
            <body>How can a programmer determine the influence of the compiler on a program's performance?</body>
            <answers>
                <answer>
                    <body>It is possible to run performance experiments using several different sets of compiler
                        settings (or even several different compiler versions, vendors). For further analysis, compilers
                        can generate an optimization report which show performed optimizations alongside the source
                        code.
                    </body>
                    <marks>
                        <mark type="regex">experiment|measure</mark>
                        <mark type="keyword">optimiz</mark>
                        <mark type="keyword">report</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="11">
            <body>What should you look for in a compiler's optimization report?</body>
            <answers>
                <answer>
                    <body>Hints about vectorization, data dependencies and memory access patterns.</body>
                    <marks>
                        <mark type="keyword">vector</mark>
                        <mark type="keyword">dependenc</mark>
                        <mark type="keyword">access</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="12">
            <body>What is a problem that can occur with tools that only see source code and binary?</body>
            <answers>
                <answer>
                    <body>The tool might not be able to correlate places in the binary with source code if there are
                        compiler optimizations that prevent doing so.
                    </body>
                    <marks>
                        <mark type="keyword">compiler</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="13">
            <body>Give an example of how you can give hints to the compiler to allow it to optimize effectively.</body>
            <answers>
                <answer>
                    <body>Using the flag -fno-alias or #pragma iv_dep, the programmer guarantees that there is no
                        aliasing, and therefore no potential overlap of memory regions, of variables in the marked code.
                        This allows further optimization as there are fewer dependencies.
                    </body>
                    <marks>
                        <mark type="keyword">alias</mark>
                        <mark type="keyword">overlap</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="14">
            <body>What two surprising insights were found by the single node performance group?</body>
            <answers>
                <answer>
                    <body>Switching the intel compiler version from 17 to 19 has a dramatic impact on performance using
                        the same compiler settings.
                        <p/>
                        The input size to the program affected the effect of different compiler flags.
                    </body>
                    <marks>
                        <mark type="keyword">version</mark>
                        <mark type="keyword">input</mark>
                    </marks>
                </answer>
            </answers>
        </question>

        <!-- Weak and Strong Scaling -->

        <question type="extended-answer" id="15">
            <body>What is the difference between strong scaling and weak scaling?</body>
            <answers>
                <answer>
                    <body>Strong scaling keeps the problem size constant and changes the number of processes working on
                        the problem, while weak scaling keeps a constant problem size per process by scaling the total
                        problem size with the number of processes.
                    </body>
                    <marks>
                        <mark type="keyword">size</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="16">
            <body>What is an alternative name for weak scaling and why?</body>
            <answers>
                <answer>
                    <body>Memory constrained scaling, because it makes better use of available per node memory resources
                        such as cache and RAM that scale with the number of processes than strong scaling does.
                    </body>
                    <marks>
                        <mark type="keyword">memory</mark>
                        <mark type="keyword">constrain</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="17">
            <body>What problem can occur when setting up a weak scaling experiment?</body>
            <answers>
                <answer>
                    <body>The program runtime might be non-linear with the input size. Assume you have a program that
                        scales in O(n^3), then doubling the number of processes and the input size would result in a
                        problem 8 times as large, or 4 times more per process.
                    </body>
                    <marks>
                        <mark type="keyword">linear</mark>
                        <mark type="keyword">size</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="18">
            <body>What is the formula for weak scaling?</body>
            <answers>
                <answer>
                    <body>TODO</body>
                    <marks></marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="19">
            <body>What is an advantage of weak scaling over strong scaling?</body>
            <answers>
                <answer>
                    <body>It reduces the impact that communication has for large number of processes by keeping the
                        ratio between communication and computation constant. In strong scaling, computation decreases
                        with number of nodes so communication starts to domniate runtime.
                    </body>
                    <marks>
                        <mark type="keyword">communication</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="20">
            <body>What is the question that is typically answered with a weak scaling test?</body>
            <answers>
                <answer>
                    <body>How much larger of a problem can we solve by scaling this? (This tends to be more relevant to
                        scientific application than &quot;how much faster can I solve this problem?&quot;)
                    </body>
                    <marks>
                        <mark type="keyword">size</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="21">
            <body>What is important when dealing with strong/weak scaling and different benchmarks?</body>
            <answers>
                <answer>
                    <body>Understand what you expect. Some benchmarks might adjust the problem size per node
                        automatically (LULESH) or spawn threads for the entire node automatically (firestarter).
                    </body>
                    <marks>
                        <mark type="keyword">size</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <!-- Affinity / Mapping -->
        <question type="extended-answer" id="22">
            <body>What is affinity and what does granularity specify?</body>
            <answers>
                <answer>
                    <body>Affinity is the distribution of software threads to hardware procs. The granularity specifies
                        where software threads can float (fine: core, socket, spread, etc.) and is set in the
                        KMP_Affinity variable.
                    </body>
                    <marks>
                        <mark type="keyword">thread</mark>
                        <mark type="keyword">proc</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="23">
            <body>Why is process affinity important? What needs to be considered?</body>
            <answers>
                <answer>
                    <body>To make good use of the NUMA architecture (memory controllers, network interconnects, etc.).
                        One needs to considered where data is located (and ensure it is actually located there using
                        e.g. first touch) and who needs to communicate with whom to reduce bottlenecks.
                    </body>
                    <marks>
                        <mark type="keyword">numa</mark>
                        <mark type="keyword">touch</mark>
                        <mark type="keyword">communicat</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <!-- MPI overhead -->
        <question type="extended-answer" id="24">
            <body>What is the difference between MPIP and PMPI?</body>
            <answers>
                <answer>
                    <body>mpiP is a MPI-profiler that uses the profiling interface of the MPI standard (PMPI) to perform
                        measurements on the MPI behavior of the program.
                    </body>
                    <marks>
                        <mark type="keyword">profil</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="25">
            <body>What information can you gain from analyzing your program with mpiP?</body>
            <answers>
                <answer>
                    <body>mpiP generates a text report showing the relevant MPI calls (with context), the time spent and
                        the amount of data transferred. This is available on a per node basis (for load imbalances) as
                        well as in aggregated form.
                    </body>
                    <marks>
                        <mark type="keyword">call</mark>
                        <mark type="keyword">time</mark>
                        <mark type="keyword">data</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="26">
            <body>What mechanism does the PMPI interface use to allow profilers to link in?</body>
            <answers>
                <answer>
                    <body>All MPI calls are made available as weak symbols, which can be overriden by the profiler.
                        These can be used to wrap the necessary calls in instrumentation.
                    </body>
                    <marks>
                        <mark type="keyword">weak</mark>
                        <mark type="keyword">symbol</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="27">
            <body>How can a program be run with mpiP?</body>
            <answers>
                <answer>
                    <body>By either linking against the profiler or using LD_Preload, which loads the profiler into the
                        application at runtime.
                    </body>
                    <marks>
                        <mark type="keyword">preload</mark>
                        <mark type="keyword">link</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="28">
            <body>What can you learn from profiling your code using mpiP? What is this useful for?</body>
            <answers>
                <answer>
                    <body>Time and data sizes (hot code regions, also on a per node base). Useful as a first step to
                        investigate potential problems (load imbalance, etc.)
                    </body>
                    <marks>
                        <mark type="keyword">time</mark>
                        <mark type="keyword">size</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="29">
            <body>What can you change in your application if you notice that your code hangs on some MPI calls?</body>
            <answers>
                <answer>
                    <body>Change the application to support nonblocking communication (i.e. do useful computation rather
                        than wait for communication resources).
                    </body>
                    <marks>
                        <mark type="keyword">block</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="30">
            <body>You observe that in your MPI application with 4 processes, rank 1 spends 32%, rank 2 28%, rank 3 11%,
                rank 4 31% of the total time in MPI calls. Which rank is likely to be overloaded?
            </body>
            <answers>
                <answer>
                    <body>Rank 3 (the rank which spends most time computing and little time waiting).</body>
                    <marks>
                        <mark type="keyword">3</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <!-- Load Balancing -->
        <question type="extended-answer" id="31">
            <body>Why does measurement in OpenMP require restructuring of the loop?</body>
            <answers>
                <answer>
                    <body>Cannot measure implicit barriers, need to convert into explicit barriers (tools like scoreP do
                        this automatically). Then measure waiting time at synchronization points.
                    </body>
                    <marks>
                        <mark type="keyword">barrier</mark>
                        <mark type="keyword">synchron</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="32">
            <body>What tools are useful for measuring load balancing with OpenMP?</body>
            <answers>
                <answer>
                    <body>Automatic instrumentation: ScoreP/Opari. Visualization: Ale (TODO?)</body>
                    <marks>
                        <mark type="keyword">instrument</mark>
                        <mark type="keyword">visual</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="33">
            <body>What is the formula for optimization potential?</body>
            <answers>
                <answer>
                    <body>
                        Imbalance time:
                        <p/>
                        User code: t_imbalance = t_max - t_avg
                        <p/>
                        Synchronization: t_imbalance = t_min - t_avg
                        <p/>
                        Imbalance ratio: r_imbalance = (t_imbalance / t_max) * (N / N-1)
                    </body>
                    <marks>
                        <mark type="keyword">time</mark>
                        <mark type="keyword">ratio</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="34">
            <body>What advantage/disadvantage does Vampyr offer for visualization?</body>
            <answers>
                <answer>
                    <body>Tons of detail to find even small problems, but can require lots of zooming and searching to
                        find the things you are looking for (information overload).
                    </body>
                    <marks>
                        <mark type="keyword">detail</mark>
                        <mark type="keyword">zoom</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="35">
            <body>In general, what is a typical cause of load imbalance?</body>
            <answers>
                <answer>
                    <body>Anything that causes global synchronization.</body>
                    <marks>
                        <mark type="keyword">sync</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <!-- Power + Energy -->
        <question type="extended-answer" id="36">
            <body>Which problems lend themselves well to higher frequency?</body>
            <answers>
                <answer>
                    <body>Compute intensive ones.</body>
                    <marks>
                        <mark type="keyword">comput</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="37">
            <body>How does core frequency affect power/eneergy consumption?</body>
            <answers>
                <answer>
                    <body>A higher core frequency implies higher power consumption, but may mean higher or lower energy
                        consumption.
                    </body>
                    <marks>
                        <mark type="keyword">power</mark>
                        <mark type="keyword">energy</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="38">
            <body>What is static and dynamic power? What is the relation of power consumption to frequency?</body>
            <answers>
                <answer>
                    <body>
                        Static power: TODO? (Something like P_static = VI_leak)
                        <p/>
                        Dynamic power: P_dyn=CfV^2
                        <p/>
                        Maximum frequency: f \correlates (V-V_th)^(\alpha)/V
                        <p/>
                        In general: Power increases with the cube of frequency.
                    </body>
                    <marks>
                        <mark type="keyword"></mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="39">
            <body>What is important when considering power/energy consumption optimization?</body>
            <answers>
                <answer>
                    <body>Think about what to optimize against and what constraints exist (cables, money spent, etc.)
                    </body>
                    <marks>
                        <mark type="keyword">optim</mark>
                        <mark type="keyword">constraint</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="40">
            <body>What is the difference between Watt, Watt hours, and Joules?</body>
            <answers>
                <answer>
                    <body>Watt is an SI Unit of Power (a rate of energy) J/s. Watt hours is a non SI measure of Energy
                        (J/s * 3600s = 3600J). Joule is the SI measure of energy.
                    </body>
                    <marks>
                        <mark type="keyword">power</mark>
                        <mark type="keyword">energy</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <!-- Dynamism -->
        <question type="extended-answer" id="41">
            <body>What is dynamism?</body>
            <answers>
                <answer>
                    <body>Execution behavior that varies over the run of a program, such as across iterations or through
                        different calculation phases.
                    </body>
                    <marks>
                        <mark type="keyword">vari</mark>
                        <mark type="keyword">iterat</mark>
                        <mark type="keyword">phase</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="42">
            <body>How can dynamism across different phases be measured?</body>
            <answers>
                <answer>
                    <body>One possibility is to introduce user regions into the source to measure the phases
                        separately.
                    </body>
                    <marks>
                        <mark type="keyword">user region</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="43">
            <body>What are some characteristics where dynamism can occur?</body>
            <answers>
                <answer>
                    <body>Execution time, cache miss rate, etc.</body>
                    <marks>
                        <mark type="keyword">time</mark>
                        <mark type="keyword">cache</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="44">
            <body>What tool is useful to track dynamism? What features are relevant?</body>
            <answers>
                <answer>
                    <body>Its CUBE! Dynamic region profiling (TODO: look this up?) and parameter based profiling are
                        relevant.
                    </body>
                    <marks>
                        <mark type="keyword">CUBE</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="45">
            <body>What is parameter based profiling? What is it useful for?</body>
            <answers>
                <answer>
                    <body>A feature of CUBE that allows to aggregate data based on a parameter such as the loop
                        iteration. It allows the user to correlate dynamism with the parameter.
                    </body>
                    <marks>
                        <mark type="keyword">param</mark>
                        <mark type="keyword">dynamism</mark>
                    </marks>
                </answer>
            </answers>
        </question>

        <!-- Lectures -->
        <!-- Introduction -->
        <question type="extended-answer" id="46">
            <body>What are some of the motivations for parallel architectures?</body>
            <answers>
                <answer>
                    <body>Performance, energy efficiency, flexibility, throughput, fault-tolerance</body>
                    <marks>
                        <mark type="keyword">perform</mark>
                        <mark type="keyword">energy</mark>
                        <mark type="keyword">flex</mark>
                        <mark type="keyword">throughput</mark>
                        <mark type="keyword">fault</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="47">
            <body>What are some usages of parallel architectures and what do they mean?</body>
            <answers>
                <answer>
                    <body>Multiple user workloads (many users on one machine), multi-programming workloads, farming (run
                        lots of sequential jobs), parallel execution.
                    </body>
                    <marks>
                        <mark type="keyword">user</mark>
                        <mark type="keyword">program</mark>
                        <mark type="keyword">farm</mark>
                        <mark type="keyword">execut</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="48">
            <body>What is farming, what potential problem can arise?</body>
            <answers>
                <answer>
                    <body>Running lots of sequential jobs, varying them over some parameters. It can create issues with
                        the scheduler if thousands of jobs are spawned.
                    </body>
                    <marks>
                        <mark type="keyword">sequen</mark>
                        <mark type="keyword">schedul</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="49">
            <body>What are some parallel programming models?</body>
            <answers>
                <answer>
                    <body>Message passing, shared memory, data parallel (OpenCL, CUDA), data flow.</body>
                    <marks>
                        <mark type="keyword">message</mark>
                        <mark type="keyword">shared</mark>
                        <mark type="keyword">data</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="50">
            <body>What are some reasons why parallel programming is more difficult than sequential programming?</body>
            <answers>
                <answer>
                    <body>Management of threads/processes, concurrency issues (race conditions/deadlocks), less
                        deterministic, ensuring scalability.
                    </body>
                    <marks>
                        <mark type="keyword">process</mark>
                        <mark type="keyword">concurren</mark>
                        <mark type="keyword">determin</mark>
                        <mark type="keyword">scalab</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="51">
            <body>What is speedup, how is it calculated? What is efficiency, how is it calculated?</body>
            <answers>
                <answer>
                    <body>Speedup is a ratio of performance (performance (p processors) / performance (1 processor)).
                        Using performance = work/time: speedup = time(1 processor)/time(p processors). Efficiency is the
                        relation of actual speedup to ideal linear scaling: efficiency = speedup(p processors)/p.
                    </body>
                    <marks>
                        <mark type="keyword">perform</mark>
                        <mark type="keyword">time</mark>
                        <mark type="keyword">linear</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="52">
            <body>Which distributed model does the SuperMUC-NG conform to?</body>
            <answers>
                <answer>
                    <body>Intra-Node: Shared Memory. Inter-Node: Distributed Memory (message passing).</body>
                    <marks>
                        <mark type="keyword">share</mark>
                        <mark type="keyword">distribut</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="53">
            <body>What is the difference between OmniPath and Infiniband Networks?</body>
            <answers>
                <answer>
                    <body>Infiniband tries to offload as much processing as possible to the network card while OmniPath
                        tries to onload as much as possible. Both Range near 100 Gb/s (approx.?)
                    </body>
                    <marks>
                        <mark type="keyword">offload</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="54">
            <body>What does the SuperMUC use as intra-/inter- island topology?</body>
            <answers>
                <answer>
                    <body>Intra island: Non-blocking tree (Multiple pairwise communications in parallel). Inter island:
                        pruned tree (like a fat tree, but grow bandwidth close to root slower than fat tree).
                    </body>
                    <marks>
                        <mark type="keyword">block</mark>
                        <mark type="keyword">prun</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="55">
            <body>What is PUE and ERE?</body>
            <answers>
                <answer>
                    <body>Power usage effectiveness (ratio of total facility power / power used by IT equipment!) (ideal
                        1, lower is better). Energy reuse effectiveness: (Total facility power - reused power/IT
                        equipment power) (ideal 0.0, range 0.0-ERE).
                    </body>
                    <marks>
                        <mark type="keyword">power</mark>
                        <mark type="keyword">usage</mark>
                        <mark type="keyword">effective</mark>
                        <mark type="keyword">reuse</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="56">
            <body>What are some SuperMUC optimizations for energy savings?</body>
            <answers>
                <answer>
                    <body>Water cooling (no fan per node), warm water cooling, heat reuse, energy aware scheduling.
                    </body>
                    <marks>
                        <mark type="keyword">water</mark>
                        <mark type="keyword">warm</mark>
                        <mark type="keyword">reuse</mark>
                        <mark type="keyword">schedul</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="57">
            <body>What architecture does automatic parallelization work well with? Where do problems start to arise?
            </body>
            <answers>
                <answer>
                    <body>Automatic parallelization can work well on shared memory systems for specific applications. It
                        struggles with NUMA, because its harder to place data correctly.
                    </body>
                    <marks>
                        <mark type="keyword">shared</mark>
                        <mark type="keyword">memory</mark>
                        <mark type="keyword">NUMA</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="58">
            <body>Aside from concurrency bugs (race conditions and deadlocks), what other source of non determinism was
                covered in the lecture?
            </body>
            <answers>
                <answer>
                    <body>Reductions on floating point values, where the result depends on the order of operations.
                    </body>
                    <marks>
                        <mark type="keyword">float</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="59">
            <body>What is the probable reason for super-linear speedup?</body>
            <answers>
                <answer>
                    <body>Better cache efficiency, probably because there is more total cache or better locality.</body>
                    <marks>
                        <mark type="keyword">cache</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="60">
            <body>How are cores arranged on the SuperMUC Phase 2 Processors?</body>
            <answers>
                <answer>
                    <body>In two rings with two interconnects.</body>
                    <marks>
                        <mark type="keyword">ring</mark>
                        <mark type="keyword">connect</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="61">
            <body>What is a resource problem inherent in MPI that OpenMP does not have?</body>
            <answers>
                <answer>
                    <body>In MPI (parts of) data structures and code are duplicated. This is a problem, because the
                        trend goes toward less memory/core.
                    </body>
                    <marks>
                        <mark type="keyword">duplicat</mark>
                        <mark type="keyword">data</mark>
                        <mark type="keyword">code</mark>
                    </marks>
                </answer>
            </answers>
        </question>
        <question type="extended-answer" id="62">
            <body>What are the levels of thread safety that an MPI implementation can offer you?</body>
            <answers>
                <answer>
                    <body>Single (No additional threads in system), funneled (MPI calls only in master thread),
                        serialized (only one thread runs MPI calls at any time), parallel (any thread, any time)
                    </body>
                    <marks>
                        <mark type="keyword">single</mark>
                        <mark type="keyword">funnel</mark>
                        <mark type="keyword">serial</mark>
                        <mark type="keyword">parallel</mark>
                    </marks>
                </answer>
            </answers>
        </question>

        <!-- Miscellaneous -->
        <question type="extended-answer" id="46">
            <body>What is CUBE not good for?</body>
            <answers>
                <answer>
                    <body>TODO</body>
                    <marks></marks>
                </answer>
            </answers>
        </question>
    </body>
</exam>